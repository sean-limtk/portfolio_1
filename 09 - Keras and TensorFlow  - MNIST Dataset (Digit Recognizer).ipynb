{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras and TensorFlow  - MNIST Dataset (Digit Recognizer)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems, and has been widely used for training and testing in the field of machine learning since its release in 1999.\n",
    "\n",
    "In this notebook, we will be using Keras (with TensorFlow as our backend) as the main package to create a simple neural network to predict digits from handwritten images. In particular, we will be calling the Functional Model API of Keras, and creating a 4-layered and 5-layered neural network.\n",
    "\n",
    "We will be experimenting with Stochastic Gradient Descent and Adam as the optimizers, as well as dropout, which is used to  prevent overfitting in neural networks.  However, we will not be tinkering with other parameters such as training epochs or hidden layer units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the label based on feature columns\n",
    "# argument = row number of train dataframe\n",
    "def plot_minst(row):\n",
    "    # Reading mnist train dataset as a pandas dataframe\n",
    "    s = pd.read_csv(\"train.csv\")\n",
    "    # Converting the pandas dataframe to a numpy matrix\n",
    "    data = np.matrix(s)\n",
    "    # Keep only the feature columns in the row\n",
    "    data = np.delete(data, row, 1)\n",
    "    # First row has 784 pixels (28*28), reshape to (28*28) np.array\n",
    "    img = data[row].reshape(28,28)\n",
    "    # Plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise row 0\n",
    "plot_minst(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADnxJREFUeJzt3X+MVPW5x/HPI7RigD8QIkWLUhvTlGC0Nxs0emO80W22pQlUrMGo4cbKVizJ7eZKVKIp0TQx5ILFxDRCSgqG2jailZB6W0Ju9PojRkRSLT+2hmBZdwMIaoGgZPW5f+zhZsU93zPMnJkz8LxfCdmZeeY78zDZz545851zvubuAhDPOVU3AKAahB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCjW/lkZuZmllvn24ZA49w9P2TDNLTlN7MuM9ttZu+a2f013F/nnntu7j8ArVN3+M1slKQnJH1P0nRJt5rZ9LIaA9BcjWz5Z0p61933uPsJSb+TNLuctgA0WyPhv0jSvmHX+7LbvsDMus1sq5ltZZ8eaB+NfOA30ocKX0q3u6+StEqSzjnnHNIPtIlGtvx9kqYOu/51Sf2NtQOgVRoJ/xuSLjOzb5jZVyXNk7SxnLYANFvdb/vdfdDMFkn6s6RRkta4+98KxuiTTz6p9ykBlMha+SGcmbHPDzRZS77kA+DMRfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQdS/RLUlmtlfSEUmfSRp0944ymsIXXXrppXWP3bNnT4mdfNnVV1+drM+ZMye3duGFFybHzp07N1nfsWNHst7V1ZVbO3ToUHJsBA2FP/Nv7v5BCY8DoIV42w8E1Wj4XdJfzOxNM+suoyEArdHo2/5r3b3fzC6QtNnMdrn7S8PvkP1R4A8D0GYa2vK7e3/284Ck5yTNHOE+q9y9gw8DgfZSd/jNbKyZjT95WdJ3Jb1TVmMAmquRt/2TJT1nZicf57fu/t+ldAWg6czdW/dkZq17MtTkiiuuSNbvuuuuZL27O/1xzujR+duXffv2JceOGTMmWS9y8cUX59ZmzZqVHPvyyy8n6wcPHqyrp1Zwd6vlfkz1AUERfiAowg8ERfiBoAg/EBThB4Jiqu8sMGrUqNzavHnzkmOfeuqpZL3o9+PYsWPJ+ooVK3JrK1euTI5NHQ4sSY899liyvn79+tzawoULk2MXL16crC9fvjxZrxJTfQCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gKOb5zwKp02e/8sorybHZ+RhyPfnkk8l60Vx7b29vsp5SdLjxtm3b6n7s/v7+ZL2zszNZ37VrV93P3WzM8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiBoMpYpRdNNn78+GQ9ddx60Tz+unXrkvWi496b6d57703Wi/5v77//fm7tkUceSY5t53n8srDlB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCo/nN7M1kn4g6YC7z8huO1/S7yVNk7RX0i3u/mHhk3E8f12aeVz7uHHjkvXjx4/X/diSNGHChNxaT09PcuwDDzyQrPf19SXr99xzT27thRdeSI49k5V5PP9vJHWdctv9kra4+2WStmTXAZxBCsPv7i9JOnzKzbMlrc0ur5WUXloFQNupd59/srsPSFL284LyWgLQCk3/br+ZdUvqbvbzADg99W7595vZFEnKfh7Iu6O7r3L3DnfvqPO5ADRBveHfKGl+dnm+pOfLaQdAqxSG38yelvSapG+ZWZ+Z/VjSo5I6zezvkjqz6wDOIIX7/O5+a07phpJ7QQXGjBmTrBfN80+cODFZ37RpU27tqquuSo597733kvVZs2Yl6zt27EjWo+MbfkBQhB8IivADQRF+ICjCDwRF+IGgWKL7DFB06u4NGzbk1m64IT0je/jwqcdsfdGSJUuS9TvvvDNZnzlzZm7t1VdfTY5dsGBBsh7h9Nr1YIluAEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAU8/xngdTpsV988cXk2MsvvzxZb/T3I7VM9tSpUxt6bIyMeX4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EFTTl+tC8334Yf7q6EWnxz527Fiy3ug8/0cffZRbS30/QUr/v9A4tvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFThPL+ZrZH0A0kH3H1GdttSSQskHczutsTd/9SsJpE2duzY3NqyZcsaeuze3t5kvWiufvr06bm1m2++OTl29erVyToaU8uW/zeSuka4/TF3vzL7R/CBM0xh+N39JUnpZV0AnHEa2edfZGZ/NbM1ZpZ+7weg7dQb/l9J+qakKyUNSFqed0cz6zazrWa2tc7nAtAEdYXf3fe7+2fu/rmk1ZJyV2N091Xu3uHuHfU2CaB8dYXfzKYMu/pDSe+U0w6AVqllqu9pSddLmmRmfZJ+Lul6M7tSkkvaK+knTewRQBNw3v6zwEMPPZRbW7p0aXJsf39/sj5jxoxk/fbbb0/WH3/88dza5s2bk2O7ukaaYUYRztsPIInwA0ERfiAowg8ERfiBoAg/EBRTfWeAhQsXJutPPPFEbi21RLbU+DLZRYf0pg4JPnHiRHJs6nBgSfr444+T9aiY6gOQRPiBoAg/EBThB4Ii/EBQhB8IivADQbFEdxt4+OGHk/Wenp5kff369bm1RYsW1dVTrQYHB5P1I0eO5NYmTpyYHDt6NL+ezcSWHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYiK1Be67775k/cEHH0zWt2/fnqx3d3fn1o4fP54c26iiU4NfcsklubWVK1cmxx46dKiellAjtvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFThefvNbKqkdZK+JulzSavcfaWZnS/p95KmSdor6RZ3/7Dgsc7K8/YXnbt+9+7dyfqnn36arHd2dibru3btStYbkfoOgSQtW7YsWT948GBu7brrrkuOHRgYSNYxsjLP2z8o6T/d/duSrpb0UzObLul+SVvc/TJJW7LrAM4QheF39wF335ZdPiJpp6SLJM2WtDa721pJc5rVJIDyndY+v5lNk/QdSa9LmuzuA9LQHwhJF5TdHIDmqfm7/WY2TtIGST9z93+a1bRbITPrlpTecQTQcjVt+c3sKxoK/np3fza7eb+ZTcnqUyQdGGmsu69y9w537yijYQDlKAy/DW3ify1pp7uvGFbaKGl+dnm+pOfLbw9As9Tytv9aSXdIetvMTh5bukTSo5L+YGY/lvQPST9qTovtr+iQ3EmTJiXrd999d7LezKm8okNyFy9enKy/9tpryfodd9yRW2Mqr1qF4Xf3lyXl7eDfUG47AFqFb/gBQRF+ICjCDwRF+IGgCD8QFOEHgio8pLfUJztLD+l96623kvWiQ3rnzZuXrJ933nnJ+pw5+cdUzZ07Nzn2pptuStbXrVuXrBd9DyB1SC+ao8xDegGchQg/EBThB4Ii/EBQhB8IivADQRF+ICiW6G6BolOeFc3F33bbbcn6jTfemFs7evRocmzRPP+mTZuS9cHBwWQd7YstPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTx/CbZs2ZKs9/T0JOvXXHNNsv7MM88k6x0d+Ysh9fb2JsciLrb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU4Xn7zWyqpHWSvibpc0mr3H2lmS2VtEDSyROzL3H3PxU81ll53n6gndR63v5awj9F0hR332Zm4yW9KWmOpFskHXX3/6q1KcIPNF+t4S/8hp+7D0gayC4fMbOdki5qrD0AVTutfX4zmybpO5Jez25aZGZ/NbM1ZjYhZ0y3mW01s60NdQqgVDWv1Wdm4yS9KOkX7v6smU2W9IEkl/SIhnYN7ix4DN72A01W2j6/JJnZVyRtkvRnd18xQn2apE3uPqPgcQg/0GSlLdRpQ6ee/bWkncODn30QeNIPJb1zuk0CqE4tn/b/q6T/lfS2hqb6JGmJpFslXamht/17Jf0k+3Aw9Vhs+YEmK/Vtf1kIP9B8pb3tB3B2IvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTV6iW6P5D03rDrk7Lb2lG79taufUn0Vq8ye7uk1ju29Hj+Lz252VZ3z19cvkLt2lu79iXRW72q6o23/UBQhB8Iqurwr6r4+VPatbd27Uuit3pV0lul+/wAqlP1lh9ARSoJv5l1mdluM3vXzO6vooc8ZrbXzN42s+1VLzGWLYN2wMzeGXbb+Wa22cz+nv0ccZm0inpbambvZ6/ddjP7fkW9TTWz/zGznWb2NzP7j+z2Sl+7RF+VvG4tf9tvZqMk9UrqlNQn6Q1Jt7r7jpY2ksPM9krqcPfK54TN7DpJRyWtO7kakpktk3TY3R/N/nBOcPf72qS3pTrNlZub1FveytL/rgpfuzJXvC5DFVv+mZLedfc97n5C0u8kza6gj7bn7i9JOnzKzbMlrc0ur9XQL0/L5fTWFtx9wN23ZZePSDq5snSlr12ir0pUEf6LJO0bdr1P7bXkt0v6i5m9aWbdVTczgsknV0bKfl5QcT+nKly5uZVOWVm6bV67ela8LlsV4R9pNZF2mnK41t3/RdL3JP00e3uL2vxK0jc1tIzbgKTlVTaTrSy9QdLP3P2fVfYy3Ah9VfK6VRH+PklTh13/uqT+CvoYkbv3Zz8PSHpOQ7sp7WT/yUVSs58HKu7n/7n7fnf/zN0/l7RaFb522crSGyStd/dns5srf+1G6quq162K8L8h6TIz+4aZfVXSPEkbK+jjS8xsbPZBjMxsrKTvqv1WH94oaX52eb6k5yvs5QvaZeXmvJWlVfFr124rXlfyJZ9sKuOXkkZJWuPuv2h5EyMws0s1tLWXho54/G2VvZnZ05Ku19BRX/sl/VzSHyX9QdLFkv4h6Ufu3vIP3nJ6u16nuXJzk3rLW1n6dVX42pW54nUp/fANPyAmvuEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wM9O2v2udRcIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise row 20\n",
    "plot_minst(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42000 * .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.as_matrix().reshape(33600, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_cv = X_cv.as_matrix().reshape(8400, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.as_matrix().reshape(28000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning, normalization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 255)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the pixel intensities are currently between the range of 0 and 255, we proceed to normalize the features, using broadcasting. In addition, we proceed to convert our labels from a class vector to binary One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train = X_train.astype('float32'); \n",
    "X_cv= X_cv.astype('float32'); \n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_cv /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Printing 2 examples of labels after conversion\n",
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "\n",
    "We proceed by fitting several simple neural network models using Keras (with TensorFlow as our backend) and collect their accuracy. The model that performs the best on the validation set will be used as the model of choice for the competition.\n",
    "\n",
    "Model 1: Simple Neural Network with 4 layers (300, 100, 100, 200)\n",
    "\n",
    "In our first model, we will use the Keras library to train a neural network with the activation function set as ReLu. To determine which class to output, we will rely on the SoftMax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model = Model(Inp, output)\n",
    "model.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Hyperparameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "sgd = optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.8541 - acc: 0.4984 - val_loss: 1.0045 - val_acc: 0.7600\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.6480 - acc: 0.8298 - val_loss: 0.4634 - val_acc: 0.8729\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.4090 - acc: 0.8835 - val_loss: 0.3615 - val_acc: 0.8979\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.3372 - acc: 0.9026 - val_loss: 0.3119 - val_acc: 0.9104\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.2978 - acc: 0.9138 - val_loss: 0.2891 - val_acc: 0.9170\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.2683 - acc: 0.9228 - val_loss: 0.2650 - val_acc: 0.9240\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.2452 - acc: 0.9296 - val_loss: 0.2556 - val_acc: 0.9260\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.2272 - acc: 0.9352 - val_loss: 0.2321 - val_acc: 0.9340\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.2101 - acc: 0.9376 - val_loss: 0.2175 - val_acc: 0.9363\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.1952 - acc: 0.9437 - val_loss: 0.2053 - val_acc: 0.9396\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.1828 - acc: 0.9469 - val_loss: 0.1955 - val_acc: 0.9426\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.1708 - acc: 0.9504 - val_loss: 0.1850 - val_acc: 0.9446\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.1613 - acc: 0.9529 - val_loss: 0.1806 - val_acc: 0.9455\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1516 - acc: 0.9561 - val_loss: 0.1763 - val_acc: 0.9470\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1432 - acc: 0.9587 - val_loss: 0.1658 - val_acc: 0.9500\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.1353 - acc: 0.9607 - val_loss: 0.1596 - val_acc: 0.9531\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1290 - acc: 0.9622 - val_loss: 0.1546 - val_acc: 0.9530\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.1217 - acc: 0.9644 - val_loss: 0.1479 - val_acc: 0.9565\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.1157 - acc: 0.9668 - val_loss: 0.1472 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.1101 - acc: 0.9682 - val_loss: 0.1410 - val_acc: 0.9581\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Using a 4 layer neural network with:\n",
    "- 20 training epochs\n",
    "- A training batch size of 100\n",
    "- Hidden layers set as (300, 100, 100, 200)\n",
    "- Learning rate of 0.1\n",
    "\n",
    "Achieved a training score of around 96-98% and a test score of around 95 - 97%.\n",
    "\n",
    "Can we do better if we were to change the optimizer? To find out, we use the Adam optimizer for our second model, while maintaining the same parameter values for all other parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "# We rely on ADAM as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 0.3393 - acc: 0.8984 - val_loss: 0.1621 - val_acc: 0.9501\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.1270 - acc: 0.9601 - val_loss: 0.1280 - val_acc: 0.9613\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.0829 - acc: 0.9744 - val_loss: 0.1099 - val_acc: 0.9660\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.0618 - acc: 0.9792 - val_loss: 0.1282 - val_acc: 0.9623\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.0448 - acc: 0.9854 - val_loss: 0.1059 - val_acc: 0.9685\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.0390 - acc: 0.9867 - val_loss: 0.1047 - val_acc: 0.9721\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.0338 - acc: 0.9888 - val_loss: 0.1142 - val_acc: 0.9710\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.0280 - acc: 0.9911 - val_loss: 0.0920 - val_acc: 0.9755\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.0216 - acc: 0.9930 - val_loss: 0.1145 - val_acc: 0.9740\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.0255 - acc: 0.9918 - val_loss: 0.1185 - val_acc: 0.9706\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.0168 - acc: 0.9941 - val_loss: 0.1162 - val_acc: 0.9737\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.0195 - acc: 0.9937 - val_loss: 0.1227 - val_acc: 0.9735\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.0209 - acc: 0.9929 - val_loss: 0.1580 - val_acc: 0.9668\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.0144 - acc: 0.9951 - val_loss: 0.1172 - val_acc: 0.9755\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.0095 - acc: 0.9973 - val_loss: 0.1217 - val_acc: 0.9755\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.0131 - acc: 0.9956 - val_loss: 0.1214 - val_acc: 0.9755\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.0162 - acc: 0.9949 - val_loss: 0.1294 - val_acc: 0.9737\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.0194 - acc: 0.9941 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.0086 - acc: 0.9975 - val_loss: 0.1293 - val_acc: 0.9750\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.0083 - acc: 0.9975 - val_loss: 0.1112 - val_acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As it turns out, it does appear to be the case that the optimizer plays a crucial part in the validation score. In particular, the model which relies on 'Adam' as its optimizer tend to perform 1.5 - 2.5% better on average. Going forward, we will use 'Adam' as our optimizer of choice.\n",
    "\n",
    "Let us see the impact of changing the learning rate from 0.1 to 0.01 on the model accuracy, using Model 2A.  We will keep 'Adam' as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 0.3382 - acc: 0.8984 - val_loss: 0.2037 - val_acc: 0.9375\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.1242 - acc: 0.9607 - val_loss: 0.1300 - val_acc: 0.9607\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.0817 - acc: 0.9747 - val_loss: 0.0971 - val_acc: 0.9695\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.0599 - acc: 0.9805 - val_loss: 0.0884 - val_acc: 0.9746\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.0480 - acc: 0.9847 - val_loss: 0.1097 - val_acc: 0.9695\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.0332 - acc: 0.9894 - val_loss: 0.1161 - val_acc: 0.9680\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.0336 - acc: 0.9885 - val_loss: 0.0990 - val_acc: 0.9737\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.0302 - acc: 0.9901 - val_loss: 0.1007 - val_acc: 0.9739\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.0183 - acc: 0.9942 - val_loss: 0.1190 - val_acc: 0.9719\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.0179 - acc: 0.9944 - val_loss: 0.1288 - val_acc: 0.9704\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.0216 - acc: 0.9925 - val_loss: 0.1219 - val_acc: 0.9726\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.0200 - acc: 0.9939 - val_loss: 0.1370 - val_acc: 0.9702\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.0177 - acc: 0.9941 - val_loss: 0.1213 - val_acc: 0.9742\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.0129 - acc: 0.9958 - val_loss: 0.1216 - val_acc: 0.9751\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.1215 - val_acc: 0.9755\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.0139 - acc: 0.9957 - val_loss: 0.1284 - val_acc: 0.9745\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.0133 - acc: 0.9961 - val_loss: 0.1160 - val_acc: 0.9781\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.0097 - acc: 0.9971 - val_loss: 0.1376 - val_acc: 0.9752\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.0168 - acc: 0.9946 - val_loss: 0.1303 - val_acc: 0.9706\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.0115 - acc: 0.9963 - val_loss: 0.1228 - val_acc: 0.9767\n"
     ]
    }
   ],
   "source": [
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaning the learning rate from 0.1 to 0.01 had a negligible effect on model accuracy.  As such, going forward we will stick with the default learning rate of 0.01.\n",
    "\n",
    "We proceed to fit a neural network with 5 hidden layers with the features in the hidden layer set as (300, 100, 100, 100, 200) respectively. To ensure that the two models are comparable, we will set the training epochs as 20, and the training batch size as 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 308,010\n",
      "Trainable params: 308,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
    "model3 = Model(Inp, output)\n",
    "model3.summary() # We have 308,010 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rely on 'Adam' as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 6s 180us/step - loss: 0.3550 - acc: 0.8940 - val_loss: 0.1763 - val_acc: 0.9488\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.1309 - acc: 0.9588 - val_loss: 0.1341 - val_acc: 0.9556\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 4s 127us/step - loss: 0.0870 - acc: 0.9721 - val_loss: 0.1046 - val_acc: 0.9700\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0631 - acc: 0.9805 - val_loss: 0.1127 - val_acc: 0.9650\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0508 - acc: 0.9831 - val_loss: 0.1136 - val_acc: 0.9676\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0434 - acc: 0.9861 - val_loss: 0.1460 - val_acc: 0.9602\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.1519 - val_acc: 0.9632\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0323 - acc: 0.9897 - val_loss: 0.1109 - val_acc: 0.9720\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0270 - acc: 0.9913 - val_loss: 0.1037 - val_acc: 0.9724\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0197 - acc: 0.9937 - val_loss: 0.1133 - val_acc: 0.9735\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.1034 - val_acc: 0.9744\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0214 - acc: 0.9933 - val_loss: 0.1222 - val_acc: 0.9735\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.1168 - val_acc: 0.9724\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.1006 - val_acc: 0.9762\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 4s 125us/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.1246 - val_acc: 0.9742\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.1153 - val_acc: 0.9750\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 4s 128us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.1142 - val_acc: 0.9754\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.1166 - val_acc: 0.9761\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 4s 126us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.1142 - val_acc: 0.9750\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 4s 127us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.1370 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Compared to our first model, adding an additional layer did not significantly improve the accuracy from our previous model. However, there are computational costs (in terms of complexity) in implementing an additional layer in our neural network. Given that the benefits of an additional layer are low while the costs are high, we will stick with the 4 layer neural network.\n",
    "\n",
    "We now proceed to include dropout (dropout rate of 0.3) in our second model to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model4 = Model(Inp, output)\n",
    "model4.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 7s 215us/step - loss: 1.6812 - acc: 0.3824 - val_loss: 0.7884 - val_acc: 0.7460\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 5s 155us/step - loss: 0.9123 - acc: 0.6985 - val_loss: 0.5103 - val_acc: 0.8381\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 5s 154us/step - loss: 0.7058 - acc: 0.7839 - val_loss: 0.3519 - val_acc: 0.9011\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 5s 154us/step - loss: 0.5865 - acc: 0.8300 - val_loss: 0.3580 - val_acc: 0.8814\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 5s 156us/step - loss: 0.5312 - acc: 0.8487 - val_loss: 0.2688 - val_acc: 0.9271\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 6s 166us/step - loss: 0.4922 - acc: 0.8613 - val_loss: 0.2610 - val_acc: 0.9310\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 6s 166us/step - loss: 0.4557 - acc: 0.8739 - val_loss: 0.2411 - val_acc: 0.9393\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 6s 167us/step - loss: 0.4308 - acc: 0.8850 - val_loss: 0.2656 - val_acc: 0.9260\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 5s 156us/step - loss: 0.4070 - acc: 0.8901 - val_loss: 0.2441 - val_acc: 0.9335\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 5s 157us/step - loss: 0.3846 - acc: 0.8965 - val_loss: 0.2571 - val_acc: 0.9255\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 5s 161us/step - loss: 0.3726 - acc: 0.9008 - val_loss: 0.2462 - val_acc: 0.9330\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 5s 162us/step - loss: 0.3604 - acc: 0.9028 - val_loss: 0.2745 - val_acc: 0.9108\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 5s 157us/step - loss: 0.3451 - acc: 0.9078 - val_loss: 0.2120 - val_acc: 0.9475\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 5s 156us/step - loss: 0.3433 - acc: 0.9085 - val_loss: 0.2152 - val_acc: 0.9460\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 5s 158us/step - loss: 0.3365 - acc: 0.9113 - val_loss: 0.2153 - val_acc: 0.9492\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 5s 159us/step - loss: 0.3314 - acc: 0.9126 - val_loss: 0.2252 - val_acc: 0.9400\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 5s 160us/step - loss: 0.3242 - acc: 0.9154 - val_loss: 0.2129 - val_acc: 0.9518\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 5s 163us/step - loss: 0.3160 - acc: 0.9176 - val_loss: 0.1999 - val_acc: 0.9548\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 5s 163us/step - loss: 0.3083 - acc: 0.9186 - val_loss: 0.2017 - val_acc: 0.9552\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 5s 156us/step - loss: 0.3057 - acc: 0.9207 - val_loss: 0.2004 - val_acc: 0.9540\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = training_epochs,\n",
    "                    validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we included a drop out rate of 0.3 to the model, the model accuracy dropped markedly from 99% to circa 95%, which is not surprising.  The tradeofff here is that we can expect the model with the drop out rate to be less prone to overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Conclusion\n",
    "In this classification exercise of MNIST data, we used Keras with TensorFlow as the backend, and tested the impact of tweaking the parameters on model accuracy.\n",
    "\n",
    "We found that tinkering with the learning rate and number of neuron layers did not offer significant improvement to model accuracy.  However, using Adam instead of Stochastic Gradient Descent as the optimizer did translate into meaningful improvement in accuracy.\n",
    "\n",
    "We also tested the impact of introducing a dropout rate to the model, to reduce overfitting, and found that the model accuracy degraded significantly, which is to be expected as a trade-off to reducing the risk of curve fitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
